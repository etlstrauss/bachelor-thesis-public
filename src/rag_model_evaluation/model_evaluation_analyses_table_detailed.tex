\begin{table}[H]
\centering
\begin{tabular}[H]{|c|c|c|c|c|}
\toprule
 & bad & average & great & kind \\
\midrule
qwen2.5-coder:32b-instruct-q8\_0 & 0 & 0 & 5 & \multirow{5}{*}{\makecell{\rotatebox[origin=c]{90}{\scriptsize{general}}}} \\
mistral-small:22b-instruct-2409-fp16 & 1 & 2 & 2 \\
llama3.1:70b & 1 & 2 & 2 \\
llama3.3:70b-instruct-q4\_K\_M & 1 & 2 & 2 \\
hf.co/matteogeniaccio/phi-4:F16 & 0 & 3 & 2 \\
\midrule
qwen2.5-coder:32b-instruct-q8\_0 & 0 & 3 & 2 & \multirow{5}{*}{\makecell{\rotatebox[origin=c]{90}{\scriptsize{programming}}}} \\
mistral-small:22b-instruct-2409-fp16 & 1 & 2 & 2 \\
llama3.1:70b & 0 & 2 & 3 \\
llama3.3:70b-instruct-q4\_K\_M & 0 & 1 & 4 \\
hf.co/matteogeniaccio/phi-4:F16 & 1 & 1 & 3 \\
\midrule
qwen2.5-coder:32b-instruct-q8\_0 & 0 & 0 & 5 & \multirow{5}{*}{\makecell{\rotatebox[origin=c]{90}{\scriptsize{programming-rag}}}} \\
mistral-small:22b-instruct-2409-fp16 & 0 & 4 & 1 \\
llama3.1:70b & 0 & 2 & 3 \\
llama3.3:70b-instruct-q4\_K\_M & 2 & 2 & 1 \\
hf.co/matteogeniaccio/phi-4:F16 & 1 & 1 & 3 \\
\bottomrule
\end{tabular}
\caption[]{Model performance for LLM models with RAG by task categories.}
\end{table}
