\begin{table}[H]
\centering
\begin{tabular}[H]{|c|c|c|c|c|}
\toprule
 model & bad & average & great & kind\\
\midrule
qwen2.5-coder:32b-instruct-q8\_0 & 0 & 1 & 4 & \multirow{5}{*}{\makecell{\rotatebox[origin=c]{90}{\scriptsize{general}}}} \\
mistral-small:22b-instruct-2409-fp16 & 2 & 1 & 2 \\
llama3.1:70b & 3 & 1 & 1 \\
llama3.3:70b-instruct-q4\_K\_M & 3 & 0 & 2 \\
hf.co/matteogeniaccio/phi-4:F16 & 2 & 1 & 2 \\
\midrule
qwen2.5-coder:32b-instruct-q8\_0 & 1 & 1 & 3 & \multirow{5}{*}{\makecell{\rotatebox[origin=c]{90}{\scriptsize{programming}}}}  \\
mistral-small:22b-instruct-2409-fp16 & 4 & 0 & 1 \\
llama3.1:70b & 4 & 0 & 1 \\
llama3.3:70b-instruct-q4\_K\_M & 1 & 2 & 2 \\
hf.co/matteogeniaccio/phi-4:F16 & 3 & 1 & 1 \\
\midrule
qwen2.5-coder:32b-instruct-q8\_0 & 0 & 0 & 5 & \multirow{5}{*}{\makecell{\rotatebox[origin=c]{90}{\scriptsize{programming-rag}}}} \\
mistral-small:22b-instruct-2409-fp16 & 3 & 2 & 0 \\
llama3.1:70b & 5 & 0 & 0 \\
llama3.3:70b-instruct-q4\_K\_M & 0 & 5 & 0 \\
hf.co/matteogeniaccio/phi-4:F16 & 2 & 3 & 0 \\
\bottomrule
\end{tabular}
\caption[]{Model performance for LLM models without RAG by task categories.}
\end{table}
